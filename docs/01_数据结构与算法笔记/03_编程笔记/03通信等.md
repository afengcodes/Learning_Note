

# 通信
## udp tcp









## can

关于can详情见 03_车辆相关笔记

封装 和 解析


## 


# 并发、线程、进程

详情教程：
[C++ 并发编程实战 第二版 ](https://www.bookstack.cn/read/CPP-Concurrency-In-Action-2ed-2019/README.md)
基础专栏：
[Article:C++11并发与多线程](https://blog.csdn.net/qq_38231713/category_10001159.html)
[Article:C++多线程笔记](https://www.notown.top/?p=463)
视频教程：
[Video:c++11并发与多线程视频课程](https://www.bilibili.com/video/BV1Yb411L7ak?p=5)


## 一、一些概念

**并发：**

有两个或两个以上的任务（独立的活动），同时发生（进行），或者说一个程序同时执行多个独立任务。
当cpu的数量少于任务数的时候，其实只是通过轮流调度来实现一种表面的并发进行。
使用并发的原因：可以同时执行多个任务，有提高性能的作用

**进程：**

可以理解为一个正在执行的可执行程序。

**线程：**

每个进程都有一个主线程，可以理解为代码的执行通路，我们可以写代码来创建其它线程，就可以实现，在同一个时间，在同一个进程执行多个任务
线程并非越多越好，线程切换也是需要时间的，需要保存恢复各种局部变量。（一般200~300个为佳）

**多进程并发与多线程并发**

**多进程实现并发**相比于多线程实现并发而言，它还**需要切换虚拟地址空间，开销更大**。
**多进程之间通信**需要借助**管道、文件、消息队列、共享内存、socket**等技术手段
**多线程之间**他们是**共享一个虚拟地址空间**的，即可以**共享内存，线程间切换开销更小**，但需要解决的一个重要问题就是：**要保证数据一致性**

以往在不同的开发平台上进行多线程开发都有不同的库、不同的函数，因此编写出来的程序一般不能跨平台。从c++11新标准开始，c++语言本身增加了对多线程的支持，使得编写的程序有了可移植性

## 二、创建线程的多种方法

**thread**
（ 一定会创建线程，如果资源太紧张导致创建不了，程序就会崩溃 ）
**async**
（也叫创建一个异步任务，但当参数被指定为launch::deferred时，就不会创建线程）（同时相比thread，它一般用于需要返回值的线程）
**A.thread创建线程**

- ① 创建一个函数，然后把该函数作为线程的入口地址
```c++  
void readTheval(int num)
{
    cout << "我是读线程" << this_thread::get_id() ;
    cout << "  我读到的数据是:" << num << endl;
    return;
}
//main函数里面：
    thread th1(readTheval, 5);//创建线程并开始执行
    th1.join();
```

- ② 创建一个类，并编写圆括号重载函数，初始化一个该类的对象，把该对象作为线程入口地址
```c++  
class CircleReLoad
{
public:
    void operator()()
    {
        cout << "创建了一个线程" << this_thread::get_id() << endl;
        /* ...  */
        cout << "线程执行结束！" << endl;
    }
};
//main函数里的：
    CircleReLoad Acase;
    thread th1(Acase);
    th1.join();
```

- ③ lambda表达式创建线程
```c++  
//main函数里
    auto OneThread = [] {
        cout << "lambda表达式创建线程" << endl;
        /* … */
        cout << this_thread::get_id() << "线程执行结束 " << endl;
    };
    thread th1(OneThread);
    th1.join();
```

- ④把某个类中的某个函数作为线程的入口地址
```c++  
class Data_
{
public:
    void GetMsg(){}
    void SaveMsh(){}
};
//main函数里
    Data_ s;
    thread oneobj(&Data_::SaveMsh,&s);
    thread twoobj(&Data_::GetMsg,&s);
    oneobj.join();
    twoobj.join();
```

**多个线程的创建、管理：**

可以用vector等容器来存放
```c++  
void TextThread()
{
     cout << "我是线程" << this_thread::get_id() << endl;
     /*  …  */
     cout << "线程" << this_thread::get_id() << "执行结束" << endl; 
}
 //main函数里     vector threadagg;
     for (int i = 0; i < 10; ++i)
     {
         threadagg.push_back(thread(TextThread));
     }
     for (int i = 0; i < 10; ++i)
     {
         threadagg[i].join();
     }
```

**join(), detach(), joinable()成员函数**

- join()：
加入/汇合，起到了让主线程等待子线程执行完毕的作用，让子线程汇合到主线程。
(一般来讲，主线程都是最后结束的，保证所有子线程都能正常的执行完毕)

- detach():
分离，将子线程和主线程分离开来，即子线程就不和主线程汇合了，主线程也不必等待子线程执行完毕
一旦detach，与主线程里的thread对象就会失去对这个子线程的控制，这个子线程就会驻留在后台运行（当此子线程执行完后，由系统自己来清理该线程的资源）
（注意如果用detach，并且该线程使用到一个主线程里的局部变量，比如说子线程中有引用或指针使指向主线程里的变量，那么就会使程序崩溃）
（当传入参数存在隐式转换的时候，也有可能出现一个问题，即主线程已经结束，传入参数的的这个变量已经被回收了，它才开始进行隐式转换并执行构造函数，这样就会引发错误）
（一句话能用join就不要detach）

- joinable()
可以判断某thread对象是否还可以join或detach，可以就返回true，否则返回false

**B.async创建线程**

async是一个函数模板，用来启动异步任务，并返回future对象，future是一个类模板
future对象里边包含线程入口函数所返回的结果（线程返回结果），后续可通过get()成员函数得到返回值。
（当你希望多次调用future的成员函数get时，可改用shared_future类模板，当然这只是将结果存储起来，多次调用的get的值是一样的）
```c++  
int TextThread(int num)
{
    cout << "我是线程" << this_thread::get_id() << endl;
    /*  …  */
    cout << "线程" << this_thread::get_id() << "执行结束" << endl;
    return num;
}
//main函数里
    future result = async(launch::async,TextThread,6);//
    cout << result.get();
```

其中：
要是launch::async省略的话，系统会把它当成launch::async | launch::deferred ，即系统会根据当前资源状况自由调度，如果资源不紧张一般会当成launch::async，即会立刻创建一个异步任务并开始执行，反之，则会当成是launch::deferred，会等到你调用成员函数get或wait的时候才由主线程去完成（类似于调用普通函数），当省略该参数时，可以用future_status判断系统最终有无创建线程）

**future_status**
```c++  
int GetAVaule(int num)
{
    cout << "我正在执行啊！" << endl;
    cout << "我的ID是:" << this_thread::get_id() << endl;
    Sleep(3000);
    return num;
}
//main函数里
    shared_future result = async(GetAVaule, 55);
    future_status status = result.wait_for(chrono::seconds(4));//等4秒看看能不能执行完(wait_for括号里可直接写4s)
    if (status == future_status::timeout)
    {
        cout << "任务超时，还没执行玩呢" << endl;
    }
    else if (status == future_status::ready)
    {
        cout << "给的时间够用，我已经准备好了" << endl;
        cout << result.get() << endl;
    }
    else if (status == future_status::deferred)
    {
        cout << "如果过你是延迟执行的参数，那就到这来" << endl;
    }
```

**packaged_task**

打包任务，把任务包装起来，是一个类模板，是一个用来包装可调用对象的可调用对象
```c++  
// TextThread为上面那个函数
    packaged_task obj(TextThread);//包装
    thread th1(ref(obj),6);//开始执行线程
    th1.join();
    future result = obj.get_future();
    cout << result.get() << endl;

```

**promise**
一个类模板，能够在某个线程中给它赋值，然后可以在其它线程中，把这个值取出来用
```c++  
void MyThread(promise& pro, int num)
{
    num *= 2;
    pro.set_value(num);
    return;
}
//main函数里
    promise my_prom;
    thread th1(MyThread, ref(my_prom), 66);
    th1.join();
    future result = my_prom.get_future();//future和promise绑定，用于获取线程返回值
    cout << result.get() << endl;
```


- 进程和程序的本质区别是动态和静态特征。

进程和程序的区别有：

（1）进程是一个动态的概念，而程序是一个静态的概念，程序是指令的有序集合，无执行含义，进程则强调执行的过程；

（2）进程具有并行特征(独立性，异步性)，程序没有；

（3）不同的进程可以包含同一程序，同一程序在执行中也可以产生多个进程。

它们的本质区别就是进程是动态的，而程序则是静态的。


- 为什么建议在文件末尾有空行？
[为什么建议在文件末尾有空行？](https://qa.1r1g.com/sf/ask/160157721/)


1.除了当移动到文本编辑器中的文件末尾时，它是一个更好的光标位置。

2.在文件末尾有一个换行符，可以简单地检查文件是否被截断。


文件末尾出现空行,以便输入流的标准读取将知道何时终止读取,通常返回EOF以指示您已到达结尾.大多数语言都可以处理EOF标记.从那时起,在DOS下,EOF标记是F6键或Ctrl-Z,对于*nix系统,它是Ctrl-D.

大多数(如果不是全部)将实际读取到EOF标记,以便运行时库从输入读取的功能将知道何时停止进一步读取.当您打开追加模式的流时,它将擦除EOF标记并写过它,直到明确调用一个关闭它将在该点插入EOF标记.

较旧的工具期待一个空行,然后是EOF标记.如今,工具可以处理空行并忽略它.

3.一些语言根据输入行定义它们的输入文件，其中每个输入行是一系列以回车符结尾的字符。如果他们的语法是这样定义的，那么文件的最后一个有效行也必须以回车符结束。

- C语言编程规范
【规则2-1-6】不允许在头文件中定义变量。
说明：

在头文件中定义的变量，在该头文件被多个源文件包含后，相当于在不同源文件中分别被定义。如果该变量是全局变量，最终编译器在链接时会因为出现重复的符号而出错。

【建议2-1-1】头文件应该自包含（self-contained）。
说明：

所有头文件要能够自给自足。换言之，用户和重构工具不需要为特别场合而包含额外的头文件。

【建议2-1-2】只有当函数只有10行甚至更少时才将其定义为内联函数。
说明：

当函数被声明为内联函数之后, 编译器会将其内联展开, 而不是按通常的函数调用机制进行调用.只要内联的函数体较小, 内联该函数可以令目标代码更加高效. 对于存取函数以及其它函数体比较短, 性能关键的函数, 鼓励使用内联。

【建议2-1-3】尽可能地避免使用前置声明，应使用 #include 包含需要的头文件。
说明：

尽可能地避免使用前置声明。可使用 #include 包含需要的头文件。 缺点：

前置声明隐藏了依赖关系，头文件改动时，用户的代码会跳过必要的重新编译过程。
前置声明可能会被库的后续更改所破坏。前置声明函数或模板有时会妨碍头文件开发者变动其 API. 例如扩大形参类型，加个自带默认参数的模板形参等等。
前置声明来自命名空间 std:: 的 symbol 时，其行为未定义。
很难判断什么时候该用前置声明，什么时候该用 #include 。极端情况下，用前置声明代替 includes 甚至都会暗暗地改变代码的含义。
reference（C++前置声明介绍）：

https://blog.csdn.net/leo_888/article/details/81124144

https://blog.csdn.net/qingzhuyuxian/article/details/92157301

【规则2-1-4】 代码入库之前,先通过代码格式化工具处理再合入。
说明：

代码格式化工具能够自动处理TAB、对齐、括号、换行等规则，保持代码的美观和统一，相关的工具有indent、astyle、uncrustify等。

【规则2-2-3】定义指针类型的变量，*应放在变量前。
正例：

c float *pfBuffer;

反例：

c float* pfBuffer;

**【建议2-2-4】如果一个布尔表达式超过标准行宽, 断行方式要统一。 **
说明：

逻辑与 (&&) 、逻辑或 (||) 操作符均位于开头。 可以考虑额外插入圆括号, 合理使用的话对增强可读性是很有帮助的。

**【建议2-2-6】空行越少越好（程序实体之间有且仅有一行空行区分，每个文件末尾都应该有且仅有一行空行）。 **
说明：

这不仅仅是规则而是原则问题了：不在万不得已，不要使用空行。尤其是：两个函数定义之间的空行不要超过 2 行，函数体首尾不要留空行，函数体中也不要随意添加空行；不同逻辑程序块之间要使用空行分隔。 基本原则是：同一屏可以显示的代码越多，越容易理解程序的控制流。当然，过于密集的代码块和过于疏松的代码块同样难看，这取决于你的判断。但通常是空行越少越好。下面的规则可以让加入的空行更有效： 函数体内开头或结尾的空行可读性微乎其微。在多重 if-else 块里加空行或许有点可读性。

**【建议2-2-7】不要在 return 表达式里加上非必须的圆括号。 **
说明：

无

【建议2-2-8】不推荐使用问号表达式（?）；如使用的话，则前后应该有一个空格。
说明：

无

【规则2-3-4】结构型的数组、多维的数组如果在定义时初始化，按照数组的矩阵结构分行书写。必须全部人工赋初值，编译器不一定会缺省赋初值。
正例：

c int aiNumbers[4][3] = { 1, 1, 1,

                 2, 4, 8,

                 3, 9, 27,

                 4, 16, 64 }

 

【规则5-1-3】宏定义中如果包含表达式或变量，表达式和变量必须用小括号括起来。
说明：

在宏定义中，对表达式和变量使用括号，可以避免可能发生的计算错误。

正例：

#define  HANDLE(A, B)   (( A ) / ( B ))
反例：

#define  HANDLE(A, B)   (A / B)
【规则5-1-6】书写数字时不要在前面添0，否则就成为8进制数。
说明：

例如 063 = (63)8 = (51)10。

【规则5-1-7】全局变量必须定义在源文件中，不允许定义在头文件中。
说明：

全局变量被定义在头文件中，如果头文件一旦被包含，包含该头文件的地方就会在Memory中生成无用的内容，浪费Memory空间，因此不允许在头文件中使用。

【规则5-1-11】定义全局变量时须进行初始化。
说明：

在C语言里，全局变量如果不初始化的话，默认为0，也就是说在全局空间里：int x =0; 跟 int x; 的效果看起来是一样的。但其实这里面的差别很大，他们的主要差别如下： 编译器在编译的时候针对这两种情况会产生两种符号放在目标文件的符号表中，已初始化的变量叫强符号变量，未初始化的变量叫弱符号变量。 连接器在连接目标文件的时候，如果遇到两个重名符号变量，会有以下处理规则： 1、如果有多个重名的强符号变量，则报错。 2、如果有一个强符号变量，多个弱符号变量，则以强符号变量为准。 3、如果没有强符号变量，但有多个重名的弱符号变量，则任选一个弱符号变量。 所以，如不初始化就可能会出现意想不到的错误。




## 三、共享数据问题

1、多个线程只读，是安全稳定的
2、多个线程同时写，或者既有读线程，也有写线程，若不加处理，就会出错

处理方法：
读的时候不能写，写的时候不能读
有两种具体实现方法：
①引入**互斥量**的概念，每次读写数据前都进行加锁保护，处理完数据后解锁
②引入**原子操作**的概念，定义某个变量为原子类型，每次进行一元运算符运算时，都能确保当前运算不被打断。

**互斥锁的特点：**
能对**一段代码片段**进行保护，操作灵活可变，但加锁解锁有一定时间开销。
**原子操作特点：**
仅适用于保护某个变量的一元运算符运算，但相对来讲额外的开销小，一般只适用于计数。

**A. 互斥锁的用法：**

- 1、mutex的成员函数lock()，unlock()
声明了一个mutex变量a后，可以用a.lock(),a.unlock()进行加锁解锁，加锁和解锁的次数必须相等。加锁期间能保证当前线程的操作不会被打断。

- 2、lock_guard
一个用类实现的，包装好了的锁
声明一个mutex变量a后，可以初始化一个类模板，例：lock_guard<mutex> obj(a);obj对象在被初始化的时候自动加锁，能在离开当前作用域后，自动析构解锁。

- 3、unique_lock
也是一个用类实现的，包装好的锁，但相比lock_guard 功能更多更灵活，没有额外参数的情况下，效果和lock_guard相同。（unique_lock <mutex> obj(a);）

第二参数可以是：
**①adopt_lock**（表示互斥量已被lock，无需再次加锁，就是说在用之前这个锁一定是已经被锁了的，这个参数lock_guard也是可以用的）
**②try_to_lock**（尝试去锁，如果没锁成功也会返回，不会卡死在那，然后可用owns_lock()得到是否上锁的信息）
```c++  
unique_lock<mutex> obj(mute,try_to_lock);
if (obj.owns_lock()) 
    {/*如果锁上了要怎么做…*/}
else 
    {/*没锁上也可以干别的事*/}
```

**③defer_lock**（用一个还没上锁的mutex变量初始化一个对象，自己可以在后续代码段中的某个位置加锁，而离开作用域时，也能帮助我们解锁，当然我们也能提前手动a.unlock()解锁）
```c++  
    mutex a;
	unique_lock<mutex> obj(a,defer_lock);
	/* 一些代码 */
	a.lock();//也可结合条件判断语句使用a.try_lock() ，若成功锁上能返回true，否则返回false 
```

unique_lock还有一个成员函数release()，可返回他所管理的mutex对象指针，并释放所有权

一般来讲，锁住的代码越少，效率越高

**使用多个互斥锁可能出现的问题：死锁**

有两个线程（A和B），有两个锁（c和d），A锁了c，还想要d的锁进行下一步操作，但这时B锁了d，但是想要c进行下一步操作。于是彼此互相锁死。

**死锁的一般避免方案：**

1、保证两个互斥锁的**上锁顺序**一致
2、或**用lock()这个函数模板，进行同时上锁**。（只有当每个锁都是可锁的状态，才会真正一次性上锁）
```c++  
例：
	mutex a;
	mutex b;
	lock(a, b);
	/*  ...  */
	a.unlock();
	b.unlock();
	
/*也可在lock(a,b)后用，以省去解锁步骤（adopt_lock参数表示，该锁已锁，不重复上锁，只在析构时，执行解锁）
	lock_guard<mutex> obj1(a,adopt_lock);
	lock_guard<mutex> obj2(b, adopt_lock);
*/
```

**B.原子操作**

**保证对某个变量进行一元操作符运算的时候，能够不被打断**，只需将该变量通过atomic这个类模板声明即可，效率比互斥锁高
```c++  
class text_class
{
public:
	atomic<int> count;
	text_class():count(0){}
	void WriteAval()
	{
		for (int i = 0; i < 100000; ++i)
		{
			++(count);
		}
	}
};
//main函数里
	text_class B;
	thread th1(&text_class::WriteAval, ref(B));
	thread th2(&text_class::WriteAval, ref(B));
	th1.join();
	th2.join();
	cout << B.count << endl;
```

**带其它功能的互斥锁**

- 1、 recursive_mutex （可重复加锁的互斥量）
如果某个线程需要对同一个锁进行多次加锁，那么可以用recursive_mutex代替mutex去声明互斥量，加了多少次，还是得解锁多少次

- 2、timed_mutex（ 带超时的互斥量 ）
①用**try_lock_for**成员函数，参数是等待的时间，等一段时间，若成功拿到就锁上并返回true，反之返回false
```c++  
    timed_mutex a;
	chrono::microseconds timeout(100);
	if (a.try_lock_for(timeout))//如果在规定时间内拿到了锁
	{
		/*  一波操作 */
		a.unlock();//解锁
	}
	else
	{
		//没拿到锁
	}
```

②用**try_lock_until**成员函数，参数是时间点，要是到了这个时间点，成功拿到锁，就锁上并返回true，没拿到返回false
```c++  
timed_mutex a;
	chrono::microseconds timeout(100);
	if (a.try_lock_until(chrono::steady_clock::now()+timeout))//如果在规定时间内拿到了锁
	{
		/*  一波操作 */
		a.unlock();//解锁
	}
	else
	{
		//没拿到锁
	}
```

**条件变量condition_variable,wait(),notify_one()**

A,B两个线程
A线程往下执行是需要条件的，
B线程可以提供一个这样的条件(不一定是一对一的关系，也可能B执行了一次，A就能拿去执行好几次了，也可能需要B执行好几次后，A才满足条件执行一次)
那么当A不满足条件的时候，就不应该再跑A线程（浪费资源），而应处于等待状态，让B去跑
```c++  
class Data_
{
	queue<int> MsgQueue;
	mutex mute;
	condition_variable my_con;
public:
	void GetMsg()
	{
		for (int i = 0; i < 10000; ++i)
		{
			unique_lock<mutex> obj(mute);
			my_con.wait(obj, [this]
			{
				if (MsgQueue.empty())
					return false;//如果空了的话就直接等待，并且解锁，这
                            //个线程就不要再跑了，等到被唤醒时，再重新加锁，往下执行
				return true;//如果没空，那就读出，继续该进程
		});
		cout << "读出" << MsgQueue.front() << endl;//到了这里就证明，队列没空，可读消息
		MsgQueue.pop();
		}
	}
	void SaveMsh()
	{
		for (int i = 0; i < 10000; ++i)
		{
			unique_lock<mutex> obj(mute);
			MsgQueue.push(i);
			cout << "装入" << i << endl;
			my_con.notify_one();//我已经加入元素，可以开始公平竞争（唤醒）
		}//不一定每次notify_one()时，另一个线程都在等待，也可能人家在干别的事
	}
};
//main函数里
Data_ var;
	thread obj1(&Data_::GetMsg, &var);
	thread obj2(&Data_::SaveMsh, &var);
	obj1.join();
	obj2.join()
```

如果允许唤醒多个线程的话，可以用notify_all()

二、其它

当我们使用单例设计模式的时候，如果我们把单例类的变量的初始化放在了线程里面（一般不推荐这样做），我们就需要确保这个初始化只会执行一次，实现的手段有以下方式：

①双重条件判断，在高效的同时，**确保初始化只能被执行一次**
比如说返回单类中某个指针，先判断是否该指针为空，若为空，则先加锁，再判断是否为空，如果为空就初始化该指针。如果不为空就返回此时的值。

②使用call_once()，能保证该函数只会被调用一次
```c++  
        once_flag g_flag;//当然这个是放在大家都能访问到的地方
        /*  ...   */
	call_once(g_flag,函数名 )
```

**浅谈线程池：**
当线程数由请求所决定，就不能简单地根据请求而创建线程。应该要程序启动的时候就把一定数量的线程创建好，放在池子里，需要用的时候就拿一个，用完放回去，以便下次调用，这种循环利用线程的方式就是线程池
一般来讲线程的创建数量，两千就是极限，一般建议200~300个，但具体情况应该具体分析，如果要调用某些api，并且api有推荐使用的线程数量，就应该根据它来。









---

信号量

sem_t 

```c++

// 初始化
#include<semaphore.h>
int sem_init(sem_t *sem,int pshared,unsigned int value);
/*
功能 创建一个信号量并初始化它的值，一个无名信号量在被使用前必须初始化
参数 sem 信号量地址  
     pshared  等于0 信号量在线程间共享   不等于0 信号在进程间共享
     value 信号量的初始值
返回 成功 0    失败 -1

*/


// 销毁
#include<semaphore,h>
int sem_destroy(sem_t *sem);
/*
功能 删除sem标识的信号量
参数 sem 信号量地址
返回 成功 0    失败 -1
*/



// P操作(减1)
#include<semaphore.h>
int sem_wait(sem_t *sem);
/*
功能 将信号量的值减1，操作前，先检查信号量(sem)的值是否为0，若为0，则阻塞，直到信号量大于0再减
参数 sem 信号量地址
返回 成功 0   失败 -1
*/

// 非阻塞减1
int sem_trywait(sem_t *sem);
// 以非阻塞的方式来对信号量进行减1操作
// 若操作前，信号量的值等于0，则对信号量的操作失败，函数立即返回

// 限时减1
int sem_timedwait(sem_t *sem,const struct timespec *abs_timeout);
// 限时尝试将信号量的值减1
// abs_timeout 绝对时间



// V操作(加1)
#include<semaphore.h>
int sem_post(sem_t *sem);
/*
功能 将信号量的值加1，并发出信号唤醒等待线程(sem_wait());
参数 sem 信号量地址
返回 成功 0    失败 -1
*/



// 获取信号量的值
#include<semaphore.h>
int sem_getvalue(sem_t *sem,int *val);
/*
功能 获取sem标识的信号量的值，保存在val中
参数 sem 信号量地址   val 保存信号量值的地址
返回 成功 0     失败 -1
*/




// sem1.c

#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<unistd.h>
#include<pthread.h>
#include<semaphore.h>


//定义信号量变量

sem_t sem;


void *func1(void *arg){
	
	int i=0;

	//申请资源 将可用资源减1
	sem_wait(&sem);

	for(i='A';i<='Z';i++){
		putchar(i);
		fflush(stdout);
		usleep(10000); //100ms
	}


	//释放资源 将可用资源加1
	sem_post(&sem);

	return NULL;

}



void *func2(void *arg){
	
	
	int i=0;

	//申请资源 将可用资源减1
	sem_wait(&sem);

	for(i='a';i<='z';i++){
		putchar(i);
		fflush(stdout);
		usleep(10000); //100ms
	}


	//释放资源 将可用资源加1
	sem_post(&sem);

	return NULL;

}





int main(){


	pthread_t tid1,tid2;

	//初始化信号量
	sem_init(&sem,0,1);


	//创建线程
	pthread_create(&tid1,NULL,func1,NULL);
	pthread_create(&tid2,NULL,func2,NULL);


	//等待线程结束
	pthread_join(tid1,NULL);
	pthread_join(tid2,NULL);

	printf("\nmain exit...\n");


	//销毁信号量
	sem_destroy(&sem);

	return 0;

}
```




---

**线程池**

**为什么要使用线程池？**
目前的大多数网络服务器，包括Web服务器、Email服务器以及数据库服务器等都具有一个共同点，就是单位时间内必须处理数目巨大的连接请求，但处理时间却相对较短。
传统多线程方案中我们采用的服务器模型则是一旦接受到请求之后，即创建一个新的线程，由该线程执行任务。任务执行完毕后，线程退出，这就是是“即时创建，即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数极其频繁，那么服务器将处于不停的创建线程，销毁线程的状态。
我们将传统方案中的线程执行过程分为三个过程：T1、T2、T3。

T1：线程创建时间
T2：线程执行时间，包括线程的同步等时间
T3：线程销毁时间
那么我们可以看出，线程本身的开销所占的比例为(T1+T3) / (T1+T2+T3)。如果线程执行的时间很短的话，这比开销可能占到20%-50%左右。如果任务执行时间很长的话，这笔开销将是不可忽略的。
除此之外，线程池能够减少创建的线程个数。通常线程池所允许的并发线程是有上界的，如果同时需要并发的线程数超过上界，那么一部分线程将会等待。而传统方案中，如果同时请求数目为2000，那么最坏情况下，系统可能需要产生2000个线程。尽管这不是一个很大的数目，但是也有部分机器可能达不到这种要求。
因此线程池的出现正是着眼于减少线程本身带来的开销。线程池采用预创建的技术，在应用程序启动之后，将立即创建一定数量的线程(N1)，放入空闲队列中。这些线程都是处于阻塞（Suspended）状态，不消耗CPU，但占用较小的内存空间。当任务到来后，缓冲池选择一个空闲线程，把任务传入此线程中运行。当N1个线程都在处理任务后，缓冲池自动创建一定数量的新线程，用于处理更多的任务。在任务执行完毕后线程也不退出，而是继续保持在池中等待下一次的任务。当系统比较空闲时，大部分线程都一直处于暂停状态，线程池自动销毁一部分线程，回收系统资源。
基于这种预创建技术，线程池将线程创建和销毁本身所带来的开销分摊到了各个具体的任务上，执行次数越多，每个任务所分担到的线程本身开销则越小，不过我们另外可能需要考虑进去线程之间同步所带来的开销

**线程池适合场景**
事实上，线程池并不是万能的。它有其特定的使用场合。线程池致力于减少线程本身的开销对应用所产生的影响，这是有前提的，前提就是线程本身开销与线程执行任务相比不可忽略。如果线程本身的开销相对于线程任务执行开销而言是可以忽略不计的，那么此时线程池所带来的好处是不明显的，比如对于FTP服务器以及Telnet服务器，通常传送文件的时间较长，开销较大，那么此时，我们采用线程池未必是理想的方法，我们可以选择“即时创建，即时销毁”的策略。
总之线程池通常适合下面的几个场合：

1.单位时间内处理任务频繁而且任务处理时间短
2.对实时性要求较高。如果接受到任务后在创建线程，可能满足不了实时要求，因此必须采用线程池进行预创建。